# ======== Base Stage ========
FROM intel/deep-learning-essentials:2025.0.2-0-devel-ubuntu24.04 AS vllm-base

# Add Intel oneAPI repo and PPA for GPU support
RUN wget -O- https://apt.repos.intel.com/intel-gpg-keys/GPG-PUB-KEY-INTEL-SW-PRODUCTS.PUB | gpg --dearmor | tee /usr/share/keyrings/oneapi-archive-keyring.gpg > /dev/null && \
    echo "deb [signed-by=/usr/share/keyrings/oneapi-archive-keyring.gpg] https://apt.repos.intel.com/oneapi all main" | tee /etc/apt/sources.list.d/oneAPI.list && \
    add-apt-repository -y ppa:kobuk-team/intel-graphics-testing

# Install dependencies and Python 3.10    
RUN apt-get update -y && \
    apt-get install -y software-properties-common && \
    add-apt-repository ppa:deadsnakes/ppa && \
    apt-get update -y && \
    apt-get install -y python3.10 python3.10-distutils && \
    curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10 && \
    apt-get install -y --no-install-recommends --fix-missing \
        curl \
        ffmpeg \
        git \
        libsndfile1 \
        libsm6 \
        libxext6 \
        libgl1 \
        lsb-release \
        numactl \
        wget \
        vim && \
    update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1 && \
    # Install Intel GPU runtime packages
    apt-get update -y && \
    apt-get install -y libze1 libze-dev libze-intel-gpu1 intel-opencl-icd libze-intel-gpu-raytracing && \
    apt-get clean && rm -rf /var/lib/apt/lists/*


WORKDIR /llm
COPY ./vllm_for_multi_arc.patch /llm/

# Set environment variables early
ENV LD_LIBRARY_PATH="$LD_LIBRARY_PATH:/usr/local/lib/"
ENV VLLM_TARGET_DEVICE=xpu
ENV VLLM_WORKER_MULTIPROC_METHOD=spawn

# Clone and install vLLM with patch
RUN git clone -b v0.8.5.post1 https://github.com/vllm-project/vllm.git && \
    cd vllm && \
    git apply /llm/vllm_for_multi_arc.patch && \
    --mount=type=cache,target=/root/.cache/pip \
    --mount=type=bind,source=.git,target=.git \
    pip install --no-cache-dir -r requirements/xpu.txt && \
    python3 setup.py install && \
    rm -f /llm/vllm_for_multi_arc.patch

CMD ["/bin/bash"]



# ======== OpenAI Serving Stage ========
FROM vllm-base AS vllm-openai

# install additional dependencies for openai api server
RUN --mount=type=cache,target=/root/.cache/pip \
    pip install accelerate hf_transfer 'modelscope!=1.15.0'

# Set additional environment for production usage
ENV VLLM_USAGE_SOURCE=production-docker-image
ENV TRITON_XPU_PROFILE=1

# install development dependencies (for testing)
RUN python3 -m pip install -e tests/vllm_test_utils
ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]
